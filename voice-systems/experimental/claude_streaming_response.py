#!/usr/bin/env python3
"""
Claude APIã¨é€£æºã—ãŸã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°å¿œç­”ã‚·ã‚¹ãƒ†ãƒ 
"""

import os
import pyaudio
import threading
import time
import anthropic
from google import genai
from google.genai import types
from dotenv import load_dotenv

load_dotenv()

def claude_streaming_response(user_message: str):
    """Claude APIã§å¿œç­”ã‚’ç”Ÿæˆã—ã€æ–‡å­—å‡ºåŠ›ã¨éŸ³å£°å‡ºåŠ›ã‚’åŒæ™‚ä¸¦è¡Œã§å®Ÿè¡Œ"""
    
    # Claude APIã§å¿œç­”ã‚’ç”Ÿæˆ
    anthropic_client = anthropic.Anthropic(
        api_key=os.environ.get("ANTHROPIC_API_KEY")
    )
    
    try:
        print(f"ğŸ’¬ ã‚ãªãŸ: {user_message}")
        print("ğŸ¤– Claudeå¿œç­”ç”Ÿæˆä¸­...")
        
        response = anthropic_client.messages.create(
            model="claude-3-5-sonnet-20241022",
            max_tokens=1000,
            temperature=0.7,
            messages=[
                {
                    "role": "user",
                    "content": user_message
                }
            ]
        )
        
        claude_response = response.content[0].text
        print("âœ… Claudeå¿œç­”å®Œäº†")
        
    except Exception as e:
        claude_response = f"ç”³ã—è¨³ã‚ã‚Šã¾ã›ã‚“ã€‚Claude APIã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}"
        print(f"âŒ Claude APIã‚¨ãƒ©ãƒ¼: {e}")
    
    # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°å‡ºåŠ›
    streaming_voice_output(claude_response)

def streaming_voice_output(text: str):
    """æ–‡å­—å‡ºåŠ›ã¨éŸ³å£°å‡ºåŠ›ã‚’åŒæ™‚ä¸¦è¡Œã§å®Ÿè¡Œ"""
    api_key = os.environ.get("GEMINI_API_KEY")
    if not api_key:
        print("ã‚¨ãƒ©ãƒ¼: GEMINI_API_KEYãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return

    # PyAudioè¨­å®š
    FORMAT = pyaudio.paInt16
    CHANNELS = 1
    RECEIVE_SAMPLE_RATE = 24000
    
    # æ–‡å­—å‡ºåŠ›ç”¨ã®å¤‰æ•°
    text_complete = False
    
    def print_text_gradually():
        """æ–‡å­—ã‚’å¾ã€…ã«å‡ºåŠ›"""
        nonlocal text_complete
        print("ğŸ¤– Claude: ", end="", flush=True)
        
        for char in text:
            print(char, end="", flush=True)
            time.sleep(0.03)  # 30msé–“éš”ã§æ–‡å­—å‡ºåŠ›ï¼ˆå°‘ã—é€Ÿãï¼‰
        
        text_complete = True
        print()  # æ”¹è¡Œ
    
    def play_streaming_audio():
        """ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°éŸ³å£°ã‚’å†ç”Ÿ"""
        pya = pyaudio.PyAudio()
        
        try:
            # éŸ³å£°ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’é–‹ã
            stream = pya.open(
                format=FORMAT,
                channels=CHANNELS,
                rate=RECEIVE_SAMPLE_RATE,
                output=True
            )
            
            client = genai.Client(api_key=api_key)
            model = "gemini-2.5-flash-preview-tts"
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            enhanced_text = f"ä»¥ä¸‹ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å†·é™ã§è½ã¡ç€ã„ãŸãƒˆãƒ¼ãƒ³ã§ã€æ—©å£ã§è©±ã—ã¦ãã ã•ã„ã€‚ãƒ—ãƒ­ãƒ•ã‚§ãƒƒã‚·ãƒ§ãƒŠãƒ«ã§é›†ä¸­ã—ãŸé›°å›²æ°—ã‚’ä¿ã¡ãªãŒã‚‰ã€ãƒ†ãƒ³ãƒã‚ˆãèª­ã¿ä¸Šã’ã¦ãã ã•ã„ï¼š\n\n{text}"
            
            contents = [
                types.Content(
                    role="user",
                    parts=[
                        types.Part.from_text(text=enhanced_text),
                    ],
                ),
            ]
            
            generate_content_config = types.GenerateContentConfig(
                temperature=1,
                response_modalities=["audio"],
                speech_config=types.SpeechConfig(
                    voice_config=types.VoiceConfig(
                        prebuilt_voice_config=types.PrebuiltVoiceConfig(
                            voice_name="Zephyr"
                        )
                    )
                ),
            )
            
            # ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°ç”Ÿæˆã¨å†ç”Ÿ
            for chunk in client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=generate_content_config,
            ):
                if (
                    chunk.candidates and
                    chunk.candidates[0].content and
                    chunk.candidates[0].content.parts and
                    chunk.candidates[0].content.parts[0].inline_data and
                    chunk.candidates[0].content.parts[0].inline_data.data
                ):
                    # éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’ç›´æ¥ã‚¹ãƒˆãƒªãƒ¼ãƒ ã«æ›¸ãè¾¼ã¿
                    audio_data = chunk.candidates[0].content.parts[0].inline_data.data
                    stream.write(audio_data)
        
        except Exception as e:
            print(f"\nğŸ”Š éŸ³å£°ã‚¨ãƒ©ãƒ¼: {e}")
        
        finally:
            if 'stream' in locals():
                stream.stop_stream()
                stream.close()
            pya.terminate()
    
    # æ–‡å­—å‡ºåŠ›ã¨éŸ³å£°å‡ºåŠ›ã‚’åŒæ™‚é–‹å§‹
    print("ğŸ”Š æ–‡å­—å‡ºåŠ›ã¨éŸ³å£°å‡ºåŠ›ã‚’åŒæ™‚é–‹å§‹...")
    
    text_thread = threading.Thread(target=print_text_gradually)
    audio_thread = threading.Thread(target=play_streaming_audio)
    
    text_thread.start()
    audio_thread.start()
    
    # ä¸¡æ–¹ã®å‡¦ç†ãŒå®Œäº†ã™ã‚‹ã¾ã§å¾…æ©Ÿ
    text_thread.join()
    audio_thread.join()
    
    print("âœ… å¿œç­”å®Œäº†\n")

if __name__ == "__main__":
    import sys
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python claude_streaming_response.py <ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸>")
        print("ä¾‹: python claude_streaming_response.py 'ã“ã‚“ã«ã¡ã¯ã€èª¿å­ã¯ã©ã†ã§ã™ã‹ï¼Ÿ'")
        sys.exit(1)
    
    user_message = " ".join(sys.argv[1:])
    claude_streaming_response(user_message)